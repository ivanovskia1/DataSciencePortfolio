{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will need several libraries\n",
    "# we will use selenium to immitate human web browsing\n",
    "# the BeautifulSoup library is very useful for parsing HTML\n",
    "# we will use the csv library objects for writing the results to a csv file\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "from lxml import html\n",
    "import time \n",
    "import smtplib\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open a file where I will store my songs\n",
    "filename = \"songs2.csv\"\n",
    "f = open(filename,\"w\")\n",
    "headers = \"Date + TimePlayed + SongName + Artist\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "#These are my desired dates to scrape \n",
    "dates = [\"01/03/2018\",\"01/04/2018\",\"01/05/2018\",\"01/06/2018\",\"01/07/2018\",\"01/08/2018\",\"01/09/2018\",\"01/10/2018\"]\n",
    "for date in dates:\n",
    "    #Loop over each page and scrape all records on that page\n",
    "    for page in range(0,10):\n",
    "        #This is where I will insert the date and page\n",
    "        url = \"http://www.hot97.com/broadcasthistory?date%5Bvalue%5D%5Bdate%5D=\" + date + \"&page=\" + str(page)\n",
    "        driver = webdriver.Chrome(\"C:\\pselenium\\chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        #Wait 5 seconds for page to load\n",
    "        driver.implicitly_wait(5)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        #This is where I will all the records \n",
    "        Content = soup.findAll(\"div\",re.compile(\"views-row views-row\"))\n",
    "\n",
    "        #Loop through each record and pull the time played, title of song, artist singing the song\n",
    "\n",
    "        for soup in Content:\n",
    "            time = soup.find(\"div\",\"views-field views-field-field-timestamp\")\n",
    "            time_cleaned = time.text\n",
    "            title = soup.find(\"div\",\"views-field views-field-field-title\")\n",
    "            title_cleaned = title.text\n",
    "            artist = soup.find(\"div\",\"views-field views-field-field-artist\")\n",
    "            artist_cleaned = artist.text  \n",
    "        #Write each record to csv\n",
    "            f.write(date + \",\" + time_cleaned + \",\" + title_cleaned + \",\" + artist_cleaned + \"\\n\")\n",
    "        driver.close()\n",
    "        \n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
