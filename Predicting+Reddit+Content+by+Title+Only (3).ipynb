{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Reddit R-rated Content by Title\n",
    "The goal of this analysis is to be able to predict by the title if the post is going to be intended for people over the age of 18 or it will be suitable for anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read Dataset that queried from SQL \n",
    "df1 = pd.read_csv(\"Over18Content.csv\")\n",
    "df2 = pd.read_csv(\"Under18Content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate two datasets\n",
    "frames = [df1, df2]\n",
    "\n",
    "df3 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of rows and columns\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Titles = []\n",
    "\n",
    "for row in df3[\"title\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Titles.append(lemma_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert each column to list and zip together to prepare it for bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Age_Allowed = []\n",
    "for row in df3[\"over_18\"]:\n",
    "    Age_Allowed.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(Titles))\n",
    "print(len(Age_Allowed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ending', 'place', 'never', 'thought', 'would']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#Sample row\n",
    "print(Titles[1500])\n",
    "print(Age_Allowed[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine both lists\n",
    "combined = zip(Titles,Age_Allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define bag_of_words function\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'call': True, '866': True, '746-5265': True, 'hottest': True, 'flight': True, 'deals-this': True, 'special': True, 'reddit': True, 'deal': True, 'site': True, 'trip': True, 'cancun': True, '550': True, 'miami': True, '250': True, 'cost': True, 'rica': True, '459': True, 'la': True, 'vega': True, '375': True, 'mention': True, 'get': True, '10': True, '1st': True, 'ticket': True, 'purchase': True, 'limited': True, 'seating': True, 'reserve': True, 'www': True}, False), ({'hiring': True, 'individual': True, 'active': True, 'top': True, 'secret': True, 'sci': True, 'clearance': True, 'expired': True, 'within': True, 'past': True, '12': True, 'month': True, 'vandenberg': True, 'air': True, 'force': True, 'base': True, 'california': True, '15.50': True, '30/hr': True, 'benefit': True}, False), ({'hiring': True, 'individual': True, 'active': True, 'top': True, 'secret': True, 'ts/sci': True, 'clearance': True, 'expired': True, 'past': True, '12': True, 'month': True, 'vandenberg': True, 'afb': True, 'ca': True, '15.50': True, '30/hr': True, 'start': True, 'benefit': True}, False)]\n"
     ]
    }
   ],
   "source": [
    "#Classify each word into True (Over 18) or False (Under 18)\n",
    "Final_Data = []\n",
    "for r, v in combined:\n",
    "    bag_of_words(r)\n",
    "    Final_Data.append((bag_of_words(r),v))\n",
    "    \n",
    "#Sample of what dataset looks like    \n",
    "print(Final_Data[1000:1003]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "#Shuffle records \n",
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "print(len(Final_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance with Unigrams \n",
      "Accuracy: 0.8716666666666667\n",
      "Most Informative Features\n",
      "                      lf = True             True : False  =     17.9 : 1.0\n",
      "                     fun = True             True : False  =     16.5 : 1.0\n",
      "                 request = True             True : False  =     15.8 : 1.0\n",
      "                    chat = True             True : False  =     15.8 : 1.0\n",
      "                    girl = True             True : False  =     13.8 : 1.0\n",
      "               subreddit = True             True : False  =     11.1 : 1.0\n",
      "                      19 = True             True : False  =      9.8 : 1.0\n",
      "                      24 = True             True : False  =      9.1 : 1.0\n",
      "                question = True            False : True   =      8.0 : 1.0\n",
      "                      18 = True             True : False  =      7.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test subsets\n",
    "train_set, test_set = Final_Data[0:1400], Final_Data[1400:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "\n",
    "refsets3 = collections. defaultdict(set)\n",
    "testsets3 = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets3[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets3[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Accuracy to Compare to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 304\n",
      "False: 296\n",
      "Null Accuracy: 50.66666666666667\n"
     ]
    }
   ],
   "source": [
    "Counter = 0\n",
    "False_Counter = 0\n",
    "for i, v in test_set:\n",
    "    if v == True:\n",
    "        Counter += 1 \n",
    "    else:\n",
    "        False_Counter += 1 \n",
    "        \n",
    "#Create counter to count how many records in test set were true vs how many were false\n",
    "print(\"True:\", Counter)\n",
    "print(\"False:\",False_Counter)\n",
    "\n",
    "print(\"Null Accuracy:\", (Counter / (Counter + False_Counter)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null accuracy for the test set is 50.43%. The naive bayes model accuractely classified 84.17% of the records, which is  33.74 % better than a naive prediction without any classifiers.\n",
    "\n",
    "Analyzing most informative features:\n",
    "The term \"lf\" appears 18.8 times in a over_18 post than under_18. Urban dictionary says \"lf\" means \"Looking for\".\n",
    "\n",
    "Words such as chat, fun, subreddit, and request also have a higher chance of appearing in over_18 posts.\n",
    "\n",
    "The numbers 22 and 24 most likely represent the age of a person, which you can see an example below. \n",
    "\n",
    "The words \"campaign\", \"idea\", and \"v\" are most likely to signal under_18 post. \n",
    "\n",
    "\"v\" stands for video upload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title  over_18\n",
      "27   24[M4F] Online/Anywhere - Bi dude searching fo...     True\n",
      "114  Vendor review - Imperialstormtrooper's GG249 2...     True\n",
      "184  24 [M4MF] Long Island/NYC Looking to watch a c...     True\n",
      "225      24 [F4m] Domme seeking bi male slave under 35     True\n",
      "426  Any sissies want a dom black top to control th...     True\n"
     ]
    }
   ],
   "source": [
    "twenty_four_example = df3[df3['title'].str.contains(\"24\")]\n",
    "print(twenty_four_example.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title  over_18\n",
      "25   30 [M4F] Portland or Online - Seeking flirty, ...     True\n",
      "73         21 [M4F] German boy looking for some fun :)     True\n",
      "252                      [B/S] Pool time fun: Update 9     True\n",
      "263                     [B/S] Pool time fun: Update 10     True\n",
      "                                                 title  over_18\n",
      "726  Which F.Priest is better overall? (dps, end ga...    False\n",
      "899  What are some of the most fun magical items/ar...    False\n",
      "924  5e: looking for suggestions for lvl 1 items th...    False\n",
      "946  What are some fun/Wacky things you have done a...    False\n"
     ]
    }
   ],
   "source": [
    "#Fun is a word that kids use a lot, but adults use it a lot in a different way.\n",
    "#This word shows the importance of making sure to mark content correctly. \n",
    "#You don't want a young child opening post by mistake from an adult looking for \"fun\"\n",
    "\n",
    "fun_example = df3[df3['title'].str.contains(\"fun\")]\n",
    "print(fun_example.head(4))\n",
    "print(fun_example.tail(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes using Bigrams\n",
    "### Build a model with bigrams to see how it will perform comapred to unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "from nltk import bigrams, trigrams\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n = 200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bag_of_words(bigrams)\n",
    "\n",
    "bigram_all_data = [(bag_of_bigrams_words(i), label) for (i, label) in combined]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(bigram_all_data)\n",
    "print(len(bigram_all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance with Ngrams Combined \n",
      "Accuracy: 0.575\n",
      "Most Informative Features\n",
      "         ('xbox', 'one') = True            False : True   =      4.4 : 1.0\n",
      "        ('want', 'play') = True             True : False  =      3.6 : 1.0\n",
      "      ('please', 'help') = True             True : False  =      3.0 : 1.0\n",
      "           ('let', \"'s\") = True             True : False  =      3.0 : 1.0\n",
      "        ('need', 'help') = True            False : True   =      2.5 : 1.0\n",
      "         ('year', 'old') = True            False : True   =      2.3 : 1.0\n",
      "   ('quick', 'question') = True            False : True   =      2.3 : 1.0\n",
      "       ('would', 'like') = True             True : False  =      2.3 : 1.0\n",
      "      ('looking', 'get') = True             True : False  =      2.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test subsets\n",
    "train_set, test_set = bigram_all_data[:1800], bigram_all_data[1800:]\n",
    "\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "#precision - Out of the ones our model said will be (pos/neg), how many did we predict correctly ? \n",
    "#recall - Out of the ones that were (pos/neg), how many did we predict correctly? \n",
    "print(\"Naive Bayes Performance with Ngrams Combined \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bigrams Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bigrams only model performs with 57.5 % accuracy, which is 26.67% lower than the unigrams only model. Nonetheless, it is still interesting to see the key words that appear in over 18 posts compared to suitable for everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
